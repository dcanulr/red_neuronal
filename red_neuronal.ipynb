{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "red_neuronal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLw48CEpCcZMapwQYJCF73",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcanulr/red_neuronal/blob/main/red_neuronal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcAeLd5aDRpB"
      },
      "source": [
        "## Funci√≥n Sigmoide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NXvHnUz-EZC",
        "outputId": "a80db370-ded8-4d66-a0ae-ed1b70606369"
      },
      "source": [
        "# Imports\n",
        "import numpy as np \n",
        "      \n",
        "# Each row is a training example, each column is a feature  [X1, X2, X3]\n",
        "X=np.array(([0,0,1],[0,1,1],[1,0,1],[1,1,1]), dtype=float)\n",
        "y=np.array(([0],[1],[1],[0]), dtype=float)\n",
        "\n",
        "# Define useful functions    \n",
        "\n",
        "# Activation function\n",
        "def sigmoid(t):\n",
        "    return 1/(1+np.exp(-t))\n",
        "\n",
        "# Derivative of sigmoid\n",
        "def sigmoid_derivative(p):\n",
        "    return p * (1 - p)\n",
        "\n",
        "# Class definition\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x,y):\n",
        "        self.input = x\n",
        "        self.weights1= np.random.rand(self.input.shape[1],4) # considering we have 4 nodes in the hidden layer\n",
        "        self.weights2 = np.random.rand(4,1)\n",
        "        self.y = y\n",
        "        self.output = np. zeros(y.shape)\n",
        "        \n",
        "    def feedforward(self):\n",
        "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "        self.layer2 = sigmoid(np.dot(self.layer1, self.weights2))\n",
        "        return self.layer2\n",
        "        \n",
        "    def backprop(self):\n",
        "        d_weights2 = np.dot(self.layer1.T, 2*(self.y -self.output)*sigmoid_derivative(self.output))\n",
        "        d_weights1 = np.dot(self.input.T, np.dot(2*(self.y -self.output)*sigmoid_derivative(self.output), self.weights2.T)*sigmoid_derivative(self.layer1))\n",
        "    \n",
        "        self.weights1 += d_weights1\n",
        "        self.weights2 += d_weights2\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.output = self.feedforward()\n",
        "        self.backprop()\n",
        "        \n",
        "\n",
        "NN = NeuralNetwork(X,y)\n",
        "for i in range(1500): # trains the NN 1,000 times\n",
        "    if i % 100 ==0: \n",
        "        print (\"for iteration # \" + str(i) + \"\\n\")\n",
        "        print (\"Input : \\n\" + str(X))\n",
        "        print (\"Actual Output: \\n\" + str(y))\n",
        "        print (\"Predicted Output: \\n\" + str(NN.feedforward()))\n",
        "        print (\"Loss: \\n\" + str(np.mean(np.square(y - NN.feedforward())))) # mean sum squared loss\n",
        "        print (\"\\n\")\n",
        "  \n",
        "    NN.train(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for iteration # 0\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.83586776]\n",
            " [0.87882026]\n",
            " [0.88008532]\n",
            " [0.906314  ]]\n",
            "Loss: \n",
            "0.38728600889770093\n",
            "\n",
            "\n",
            "for iteration # 100\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.46103398]\n",
            " [0.53535373]\n",
            " [0.50503478]\n",
            " [0.52904469]]\n",
            "Loss: \n",
            "0.23833183552187565\n",
            "\n",
            "\n",
            "for iteration # 200\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.1584369 ]\n",
            " [0.73904422]\n",
            " [0.70732774]\n",
            " [0.35449119]]\n",
            "Loss: \n",
            "0.07613030792556784\n",
            "\n",
            "\n",
            "for iteration # 300\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.06489017]\n",
            " [0.89929386]\n",
            " [0.8876201 ]\n",
            " [0.12316365]]\n",
            "Loss: \n",
            "0.010537747121030224\n",
            "\n",
            "\n",
            "for iteration # 400\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.04188541]\n",
            " [0.93547842]\n",
            " [0.92784524]\n",
            " [0.07744875]]\n",
            "Loss: \n",
            "0.004280509841471011\n",
            "\n",
            "\n",
            "for iteration # 500\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.03223622]\n",
            " [0.95034188]\n",
            " [0.94448937]\n",
            " [0.05906547]]\n",
            "Loss: \n",
            "0.002518815786185539\n",
            "\n",
            "\n",
            "for iteration # 600\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.02681909]\n",
            " [0.95862322]\n",
            " [0.95378383]\n",
            " [0.0489312 ]]\n",
            "Loss: \n",
            "0.0017403745692993172\n",
            "\n",
            "\n",
            "for iteration # 700\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.02329244]\n",
            " [0.96399585]\n",
            " [0.95981908]\n",
            " [0.04240117]]\n",
            "Loss: \n",
            "0.0013128004760348908\n",
            "\n",
            "\n",
            "for iteration # 800\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.02078412]\n",
            " [0.96781061]\n",
            " [0.9641058 ]\n",
            " [0.03778743]]\n",
            "Loss: \n",
            "0.0010461050100797962\n",
            "\n",
            "\n",
            "for iteration # 900\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.01889242]\n",
            " [0.97068532]\n",
            " [0.96733645]\n",
            " [0.03432387]]\n",
            "Loss: \n",
            "0.0008653273701500713\n",
            "\n",
            "\n",
            "for iteration # 1000\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.01740513]\n",
            " [0.97294483]\n",
            " [0.96987559]\n",
            " [0.03160993]]\n",
            "Loss: \n",
            "0.0007353971846425493\n",
            "\n",
            "\n",
            "for iteration # 1100\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.01619895]\n",
            " [0.97477732]\n",
            " [0.97193462]\n",
            " [0.02941455]]\n",
            "Loss: \n",
            "0.0006378677298674698\n",
            "\n",
            "\n",
            "for iteration # 1200\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.01519696]\n",
            " [0.97629993]\n",
            " [0.97364516]\n",
            " [0.02759446]]\n",
            "Loss: \n",
            "0.0005621682337045349\n",
            "\n",
            "\n",
            "for iteration # 1300\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.01434852]\n",
            " [0.97758964]\n",
            " [0.97509377]\n",
            " [0.02605572]]\n",
            "Loss: \n",
            "0.000501831348456867\n",
            "\n",
            "\n",
            "for iteration # 1400\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]]\n",
            "Actual Output: \n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            "[[0.01361883]\n",
            " [0.97869933]\n",
            " [0.97633991]\n",
            " [0.024734  ]]\n",
            "Loss: \n",
            "0.00045269036355737507\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhZb0_Bh-sVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff8bc18-b36a-47e0-fd4e-f2d88481af4d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "\n",
        "  def __init__(self):\n",
        "    np.random.seed(1)\n",
        "    \n",
        "    self.synaptic_weights = 2*np.random.random((3,1)) - 1\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "  def sigmoid_derivative(self,x):\n",
        "    return x*(1-x)\n",
        "\n",
        "  def train(self, training_inputs, training_outputs, training_iterations):\n",
        "\n",
        "    for iteration in range(training_iterations):\n",
        "\n",
        "      output = self.think(training_inputs)\n",
        "      error = training_outputs - output\n",
        "      adjustments = np.dot(training_inputs.T, error*self.sigmoid_derivative(output))\n",
        "      self.synaptic_weights += adjustments\n",
        "\n",
        "  def think(self, inputs):\n",
        "    inputs = inputs.astype(float)\n",
        "    output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
        "\n",
        "    return output\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Random synaptic weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                            [1,1,1],\n",
        "                            [1,0,1],\n",
        "                            [0,1,1]])\n",
        "    \n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    neural_network.train(training_inputs, training_outputs, 10000)\n",
        "\n",
        "    print(\"Synaptics weights after training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    A = str(input(\"Input 1: \"))\n",
        "    B = str(input(\"Input 2: \"))\n",
        "    C = str(input(\"Input 3: \"))\n",
        "\n",
        "    print(\"New situation: input data = \", A, B, C)\n",
        "    print(\"Output data: \")\n",
        "    print(neural_network.think(np.array([A,B,C])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random synaptic weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Synaptics weights after training: \n",
            "[[ 9.67299303]\n",
            " [-0.2078435 ]\n",
            " [-4.62963669]]\n",
            "Input 1: 1\n",
            "Input 2: 1\n",
            "Input 3: 0\n",
            "New situation: input data =  1 1 0\n",
            "Output data: \n",
            "[0.9999225]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH9mWaolBVQN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzB2TkerBn4T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}